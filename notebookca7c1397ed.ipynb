{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1439227,"sourceType":"datasetVersion","datasetId":843370},{"sourceId":8108889,"sourceType":"datasetVersion","datasetId":4789828},{"sourceId":8283698,"sourceType":"datasetVersion","datasetId":4789802}],"dockerImageVersionId":29860,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import libraries","metadata":{}},{"cell_type":"code","source":"pip install torch pytorch-crf unidecode","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:23.570269Z","iopub.execute_input":"2024-05-02T16:14:23.570796Z","iopub.status.idle":"2024-05-02T16:14:32.859778Z","shell.execute_reply.started":"2024-05-02T16:14:23.570727Z","shell.execute_reply":"2024-05-02T16:14:32.858752Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (1.4.0)\nCollecting pytorch-crf\n  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\nRequirement already satisfied: unidecode in /opt/conda/lib/python3.6/site-packages (1.1.1)\nInstalling collected packages: pytorch-crf\nSuccessfully installed pytorch-crf-0.7.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport string\nfrom unidecode import unidecode\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\nfrom transformers import AdamW, BertModel, AutoConfig, AutoTokenizer\nfrom torch.optim import Adam\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, get_linear_schedule_with_warmup\nimport time\nimport datetime\nfrom sklearn.model_selection import train_test_split\nfrom torchcrf import CRF","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:32.862147Z","iopub.execute_input":"2024-05-02T16:14:32.862480Z","iopub.status.idle":"2024-05-02T16:14:40.216308Z","shell.execute_reply.started":"2024-05-02T16:14:32.862426Z","shell.execute_reply":"2024-05-02T16:14:40.215622Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():  \n    device = torch.device(\"cuda\")\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n    \nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:40.217841Z","iopub.execute_input":"2024-05-02T16:14:40.218138Z","iopub.status.idle":"2024-05-02T16:14:40.272657Z","shell.execute_reply.started":"2024-05-02T16:14:40.218099Z","shell.execute_reply":"2024-05-02T16:14:40.271883Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"We will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Read data","metadata":{}},{"cell_type":"code","source":"# nlp_train=pd.read_csv(\"train.csv\", index_col=[0])\n# nlp_test=pd.read_csv(\"test.csv\",index_col=[0],encoding=\"windows-1252\") \n\nnlp_train=pd.read_csv(\"/kaggle/input/nlp-project-train/train.csv\", index_col=[0])\nnlp_test=pd.read_csv(\"/kaggle/input/nlp-project-train/test.csv\",index_col=[0],encoding=\"windows-1252\")","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:40.274062Z","iopub.execute_input":"2024-05-02T16:14:40.274481Z","iopub.status.idle":"2024-05-02T16:14:40.549200Z","shell.execute_reply.started":"2024-05-02T16:14:40.274428Z","shell.execute_reply":"2024-05-02T16:14:40.548498Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Functions to manipulate data","metadata":{}},{"cell_type":"code","source":"def convert_to_ascii(text):\n    return unidecode(text)\n\ndef remove_punctuations(text):\n    for punctuation in string.punctuation:\n        text = text.replace(punctuation, '')\n        text = text.replace('  ', ' ')\n    return text.strip()","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:40.553004Z","iopub.execute_input":"2024-05-02T16:14:40.553361Z","iopub.status.idle":"2024-05-02T16:14:40.558781Z","shell.execute_reply.started":"2024-05-02T16:14:40.553323Z","shell.execute_reply":"2024-05-02T16:14:40.557709Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Apply remove punctuations functions to Sentence column\nnlp_train['Sentence'] = nlp_train['Sentence'].apply(remove_punctuations)\n\n# applying the conversion functions\nnlp_train[\"Label\"] = nlp_train[\"Sentence\"]\nnlp_train[\"Sentence\"] = nlp_train[\"Sentence\"].apply(convert_to_ascii)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:40.561064Z","iopub.execute_input":"2024-05-02T16:14:40.561388Z","iopub.status.idle":"2024-05-02T16:14:44.425521Z","shell.execute_reply.started":"2024-05-02T16:14:40.561330Z","shell.execute_reply":"2024-05-02T16:14:44.424791Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"nlp_test","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:44.427014Z","iopub.execute_input":"2024-05-02T16:14:44.427319Z","iopub.status.idle":"2024-05-02T16:14:44.447836Z","shell.execute_reply.started":"2024-05-02T16:14:44.427279Z","shell.execute_reply":"2024-05-02T16:14:44.446874Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                               Sentence\nID                                                     \n0      tr ekonomi ve politika haberleri turkiye nin ...\n1                                           uye girisi \n2                                 son guncelleme 12:12 \n3       Imrali Mit gorusmesi ihtiyac duyuldukca oluyor \n4      Suriye deki silahli selefi muhalifler yeni ku...\n...                                                 ...\n1152       Yuregir Adana ilimize ait sirin bir ilcedir \n1153  yuze guluculugun at oynattigi bir aydinlar ort...\n1154  zavalli adami oracikta astilar ve hic kimse se...\n1155  zengin cocuklarina ariz munasebetsizlikler fak...\n1156                     senin acin hepimizin acisidir \n\n[1157 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tr ekonomi ve politika haberleri turkiye nin ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>uye girisi</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>son guncelleme 12:12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Imrali Mit gorusmesi ihtiyac duyuldukca oluyor</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Suriye deki silahli selefi muhalifler yeni ku...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1152</th>\n      <td>Yuregir Adana ilimize ait sirin bir ilcedir</td>\n    </tr>\n    <tr>\n      <th>1153</th>\n      <td>yuze guluculugun at oynattigi bir aydinlar ort...</td>\n    </tr>\n    <tr>\n      <th>1154</th>\n      <td>zavalli adami oracikta astilar ve hic kimse se...</td>\n    </tr>\n    <tr>\n      <th>1155</th>\n      <td>zengin cocuklarina ariz munasebetsizlikler fak...</td>\n    </tr>\n    <tr>\n      <th>1156</th>\n      <td>senin acin hepimizin acisidir</td>\n    </tr>\n  </tbody>\n</table>\n<p>1157 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sentences_train, labels_train = nlp_train.Sentence.values, nlp_train.Label.values","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:44.449305Z","iopub.execute_input":"2024-05-02T16:14:44.449856Z","iopub.status.idle":"2024-05-02T16:14:44.454395Z","shell.execute_reply.started":"2024-05-02T16:14:44.449668Z","shell.execute_reply":"2024-05-02T16:14:44.453521Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:44.455558Z","iopub.execute_input":"2024-05-02T16:14:44.455947Z","iopub.status.idle":"2024-05-02T16:14:51.351964Z","shell.execute_reply.started":"2024-05-02T16:14:44.455893Z","shell.execute_reply":"2024-05-02T16:14:51.351057Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81c4c2308c8149f4a8756bd4794f0c4f"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=251003.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de9b03513bb24f508cc8e2a20b0d2ddc"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=60.0, style=ProgressStyle(description_w…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7bc4867b4af474bb8ba8f050e5d5f15"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Functions to segment data","metadata":{}},{"cell_type":"code","source":"def segment_text(sentence, label, max_length=512, overlap=50):\n    tokens = tokenizer.tokenize(sentence)\n    new = []\n    if len(tokens) <= max_length:\n        return sentence, label\n    else: \n        return None, None\n    \n    \ndef data_segments(sentences, labels, max_length=128):\n    all_text = []\n    all_labels = []\n\n    for sentence, label in zip(sentences, labels):\n        segment_s, segment_l = segment_text(sentence, label, max_length=max_length, overlap=50)\n        if segment_s:\n            all_text.append(segment_s)\n            all_labels.append(segment_l)\n            \n    return all_text, all_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:51.353260Z","iopub.execute_input":"2024-05-02T16:14:51.353598Z","iopub.status.idle":"2024-05-02T16:14:51.361849Z","shell.execute_reply.started":"2024-05-02T16:14:51.353533Z","shell.execute_reply":"2024-05-02T16:14:51.360702Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_sentences, train_labels = data_segments(sentences_train, labels_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:14:51.362923Z","iopub.execute_input":"2024-05-02T16:14:51.363301Z","iopub.status.idle":"2024-05-02T16:15:20.177177Z","shell.execute_reply.started":"2024-05-02T16:14:51.363258Z","shell.execute_reply":"2024-05-02T16:15:20.176445Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"indices=tokenizer.batch_encode_plus(train_sentences,max_length=128,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\ninput_ids=indices[\"input_ids\"]\nattention_masks=indices[\"attention_mask\"]\nprint(input_ids[0])\nprint(train_sentences[0])\nprint(attention_masks[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:15:20.178391Z","iopub.execute_input":"2024-05-02T16:15:20.178732Z","iopub.status.idle":"2024-05-02T16:15:52.268809Z","shell.execute_reply.started":"2024-05-02T16:15:20.178684Z","shell.execute_reply":"2024-05-02T16:15:52.267865Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[2, 16751, 1066, 8725, 1992, 29252, 4456, 22063, 5484, 18740, 13526, 1027, 26905, 24419, 3575, 1028, 2031, 21070, 2194, 1996, 5538, 14330, 2033, 2002, 9474, 2293, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nsinif havuz ve acik deniz calismalariyla tum dunyada gecerli basarili bir standart olusturmustur\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"indices=tokenizer.batch_encode_plus(train_labels,max_length=128,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\noutput_ids=indices[\"input_ids\"]\nprint(output_ids[0])\nprint(train_labels[0])","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:15:52.270554Z","iopub.execute_input":"2024-05-02T16:15:52.270997Z","iopub.status.idle":"2024-05-02T16:16:23.247505Z","shell.execute_reply.started":"2024-05-02T16:15:52.270937Z","shell.execute_reply":"2024-05-02T16:16:23.246569Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[2, 3825, 8725, 1992, 2416, 4456, 24513, 2525, 5292, 5953, 4165, 1996, 5538, 27202, 2293, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nsınıf havuz ve açık deniz çalışmalarıyla tüm dünyada geçerli başarılı bir standart oluşturmuştur\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Prepare train and test data","metadata":{}},{"cell_type":"code","source":"# Use 99% for training and 1% for validation.\ntrain_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, output_ids, \n                                                            random_state=42, test_size=0.2)\n# Do the same for the masks.\ntrain_masks, validation_masks, _, _ = train_test_split(attention_masks, output_ids,\n                                             random_state=42, test_size=0.2)\n\n# Convert all of our data into torch tensors, the required datatype for our model\ntrain_inputs = torch.tensor(train_inputs)\nvalidation_inputs = torch.tensor(validation_inputs)\ntrain_labels = torch.tensor(train_labels, dtype=torch.long)\nvalidation_labels = torch.tensor(validation_labels, dtype=torch.long)\ntrain_masks = torch.tensor(train_masks, dtype=torch.long)\nvalidation_masks = torch.tensor(validation_masks, dtype=torch.long)\n\n\nbatch_size = 16\n\n# Create the DataLoader for our training set.\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_loader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size, pin_memory=True)\n\n# Create the DataLoader for our validation set.\nvalidation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\nvalidation_sampler = SequentialSampler(validation_data)\nvalidation_loader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:16:23.248829Z","iopub.execute_input":"2024-05-02T16:16:23.249169Z","iopub.status.idle":"2024-05-02T16:16:24.215327Z","shell.execute_reply.started":"2024-05-02T16:16:23.249120Z","shell.execute_reply":"2024-05-02T16:16:24.214250Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def format_time(elapsed):\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    return str(datetime.timedelta(seconds=elapsed_rounded))\n\n# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:16:24.216793Z","iopub.execute_input":"2024-05-02T16:16:24.217147Z","iopub.status.idle":"2024-05-02T16:16:24.223519Z","shell.execute_reply.started":"2024-05-02T16:16:24.217097Z","shell.execute_reply":"2024-05-02T16:16:24.222623Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class BertSeq2Seq(nn.Module):\n    def __init__(self, model_name, config):\n        super(BertSeq2Seq, self).__init__()\n        self.config = config\n        self.bert_encoder = BertModel.from_pretrained(model_name, config=config)\n        self.decoder = nn.GRU(input_size=config.hidden_size, \n                              hidden_size=config.hidden_size, \n                              num_layers=1, \n                              batch_first=True)\n        self.out = nn.Linear(config.hidden_size, config.vocab_size)\n\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        # Get outputs from the encoder\n        encoder_outputs = self.bert_encoder(input_ids, attention_mask=attention_mask)\n        \n        # Check if the encoder outputs are in a tuple and get the last hidden state\n        if isinstance(encoder_outputs, tuple):  # Older versions might return a tuple\n            encoder_last_hidden_state = encoder_outputs[0]\n        else:  # Newer versions return a model-specific output object\n            encoder_last_hidden_state = encoder_outputs.last_hidden_state\n\n        # Pass the last hidden state to the decoder\n        decoder_outputs, _ = self.decoder(encoder_last_hidden_state)\n        logits = self.out(decoder_outputs)\n\n        outputs = (logits,)\n\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.config.vocab_size), labels.view(-1))\n            outputs = (loss,) + outputs\n\n        return outputs  # returns (loss, logits) if labels provided","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:16:24.224978Z","iopub.execute_input":"2024-05-02T16:16:24.225395Z","iopub.status.idle":"2024-05-02T16:16:24.237416Z","shell.execute_reply.started":"2024-05-02T16:16:24.225332Z","shell.execute_reply":"2024-05-02T16:16:24.236302Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\nconfig.vocab_size = 32000\nconfig.num_attention_heads = 8\n\n# Initialize your model with the loaded configuration\nmodel = BertSeq2Seq(\"dbmdz/bert-base-turkish-cased\", config)\n\noptimizer = AdamW(model.parameters(),\n                  lr = 2e-5,\n                  betas=[0.9,0.999],\n                  eps = 1e-6\n                )\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n# total_steps = len(train_dataloader) * epochs\ntotal_steps = 1\nepochs = 1\n\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:16:24.238972Z","iopub.execute_input":"2024-05-02T16:16:24.239394Z","iopub.status.idle":"2024-05-02T16:17:24.568185Z","shell.execute_reply.started":"2024-05-02T16:16:24.239337Z","shell.execute_reply":"2024-05-02T16:17:24.567288Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=445018508.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bb13aec595c4fe7b145b5393ca32b94"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Function to measure time elapsed\n# def format_time(elapsed):\n#     return str(datetime.timedelta(seconds=int(round((elapsed)))))\n\n# for epoch_i in range(epochs):\n#     print(f'======== Epoch {epoch_i + 1} / {epochs} ========')\n#     print('Training...')\n\n#     total_loss = 0\n#     model.train()\n#     t0 = time.time()  # Start time for the epoch\n\n#     for step, batch in enumerate(train_loader):\n#         if step % 30 == 0 and step != 0:\n#             elapsed = format_time(time.time() - t0)\n#             print(f'  Batch {step:>5,} of {len(train_loader):>5,}. Elapsed: {elapsed}.')\n\n#         b_input_ids = batch[0].to(device)\n#         b_input_mask = batch[1].to(device)\n#         b_labels = batch[2].to(device)\n\n#         model.zero_grad()\n#         outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n#         loss = outputs[0] if isinstance(outputs, tuple) else outputs.loss\n\n#         total_loss += loss.item()\n#         loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n#         optimizer.step()\n#         scheduler.step()\n\n#     avg_train_loss = total_loss / len(train_loader)\n#     print(f\"  Average training loss: {avg_train_loss:.2f}\")\n\n#     # Validation\n#     print(\"Running Validation...\")\n#     model.eval()\n#     eval_loss, eval_accuracy, nb_eval_steps = 0, 0, 0\n\n#     for batch in validation_loader:\n#         b_input_ids = batch[0].to(device)\n#         b_input_mask = batch[1].to(device)\n#         b_labels = batch[2].to(device)\n\n#         with torch.no_grad():\n#             outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n#             logits = outputs[1] if isinstance(outputs, tuple) else outputs.logits\n\n#         logits = logits.detach().cpu().numpy()\n#         label_ids = b_labels.to('cpu').numpy()\n\n#         # Example of how you might calculate accuracy for seq2seq. Adjust as necessary.\n#         tmp_eval_accuracy = np.mean(np.argmax(logits, axis=-1) == label_ids)\n#         eval_accuracy += tmp_eval_accuracy\n#         nb_eval_steps += 1\n\n#     print(f\"  Validation Accuracy: {eval_accuracy / nb_eval_steps:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:17:24.569710Z","iopub.execute_input":"2024-05-02T16:17:24.570157Z","iopub.status.idle":"2024-05-02T16:17:24.576133Z","shell.execute_reply.started":"2024-05-02T16:17:24.570093Z","shell.execute_reply":"2024-05-02T16:17:24.574844Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class BertBiLSTMCRF(nn.Module):\n    def __init__(self, bert_model, num_labels, lstm_hidden_dim, lstm_layers=1, bidirectional=True, dropout=0.1):\n        super(BertBiLSTMCRF, self).__init__()\n        self.num_labels = num_labels\n        self.lstm_hidden_dim = lstm_hidden_dim\n        self.bert = BertModel.from_pretrained(bert_model)\n        self.dropout = nn.Dropout(dropout)\n        self.bilstm = nn.LSTM(self.bert.config.hidden_size, lstm_hidden_dim, num_layers=lstm_layers, bidirectional=bidirectional, batch_first=True, dropout=dropout)\n        self.hidden2tag = nn.Linear(lstm_hidden_dim * 2 if bidirectional else lstm_hidden_dim, num_labels)\n        self.crf = CRF(num_labels, batch_first=True)\n\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)\n        sequence_output = self.dropout(outputs[0])\n        lstm_output, _ = self.bilstm(sequence_output)\n        emissions = self.hidden2tag(lstm_output)\n        if labels is not None:\n            loss = -self.crf(emissions, labels, mask=attention_mask.byte())\n            return loss\n        else:\n            predictions = self.crf.decode(emissions, mask=attention_mask.byte())\n            return predictions\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:17:24.577665Z","iopub.execute_input":"2024-05-02T16:17:24.578112Z","iopub.status.idle":"2024-05-02T16:17:24.593538Z","shell.execute_reply.started":"2024-05-02T16:17:24.578046Z","shell.execute_reply":"2024-05-02T16:17:24.592682Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n# encoded_batch = tokenizer(train_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n# input_ids = encoded_batch['input_ids']\n# attention_mask_train = encoded_batch['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:17:24.594844Z","iopub.execute_input":"2024-05-02T16:17:24.595254Z","iopub.status.idle":"2024-05-02T16:17:24.607874Z","shell.execute_reply.started":"2024-05-02T16:17:24.595198Z","shell.execute_reply":"2024-05-02T16:17:24.607192Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Assume sentences_train and labels_train are your input IDs and labels respectively\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:17:24.609015Z","iopub.execute_input":"2024-05-02T16:17:24.609288Z","iopub.status.idle":"2024-05-02T16:17:24.618153Z","shell.execute_reply.started":"2024-05-02T16:17:24.609251Z","shell.execute_reply":"2024-05-02T16:17:24.617458Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"unique_labels = nlp_train['Label'].unique()\nnum_labels = len(unique_labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:17:24.619544Z","iopub.execute_input":"2024-05-02T16:17:24.619893Z","iopub.status.idle":"2024-05-02T16:17:24.667515Z","shell.execute_reply.started":"2024-05-02T16:17:24.619844Z","shell.execute_reply":"2024-05-02T16:17:24.666909Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = BertBiLSTMCRF('dbmdz/bert-base-turkish-cased', num_labels=num_labels, lstm_hidden_dim=256)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:17:24.668553Z","iopub.execute_input":"2024-05-02T16:17:24.668860Z","iopub.status.idle":"2024-05-02T16:17:42.796416Z","shell.execute_reply.started":"2024-05-02T16:17:24.668821Z","shell.execute_reply":"2024-05-02T16:17:42.795630Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n  \"num_layers={}\".format(dropout, num_layers))\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"BertBiLSTMCRF(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (bilstm): LSTM(768, 256, batch_first=True, dropout=0.1, bidirectional=True)\n  (hidden2tag): Linear(in_features=512, out_features=40878, bias=True)\n  (crf): CRF(num_tags=40878)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=5e-5)\nepochs = 4\n\nmodel.train()\n\nfor epoch in range(epochs):\n    total_loss = 0\n    for step, batch in enumerate(train_dataloader):\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        model.zero_grad()\n\n        # Forward pass\n        loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n        total_loss += loss.item()\n\n        # Backward pass\n        loss.backward()\n        optimizer.step()\n\n    avg_loss = total_loss / len(train_dataloader)\n    print(f\"Average loss for epoch {epoch+1}: {avg_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-02T16:17:42.798015Z","iopub.execute_input":"2024-05-02T16:17:42.798342Z","iopub.status.idle":"2024-05-02T16:17:43.667413Z","shell.execute_reply.started":"2024-05-02T16:17:42.798293Z","shell.execute_reply":"2024-05-02T16:17:43.665669Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-36b6448513bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-b6e16610ff36>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0memissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchcrf/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, emissions, tags, mask, reduction)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# shape: (batch_size,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_normalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memissions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;31m# shape: (batch_size,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mllh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerator\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchcrf/__init__.py\u001b[0m in \u001b[0;36m_compute_normalizer\u001b[0;34m(self, emissions, mask)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m# and emitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;31m# shape: (batch_size, num_tags, num_tags)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mnext_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_score\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbroadcast_emissions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;31m# Sum over all possible current tags, but we're in score space, so a sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 199.20 GiB (GPU 0; 15.89 GiB total capacity; 11.21 GiB already allocated; 3.84 GiB free; 11.33 GiB reserved in total by PyTorch)"],"ename":"RuntimeError","evalue":"CUDA out of memory. Tried to allocate 199.20 GiB (GPU 0; 15.89 GiB total capacity; 11.21 GiB already allocated; 3.84 GiB free; 11.33 GiB reserved in total by PyTorch)","output_type":"error"}]}]}