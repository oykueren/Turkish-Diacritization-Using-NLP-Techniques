{"cells":[{"cell_type":"markdown","metadata":{},"source":["Import libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:25:51.068646Z","iopub.status.busy":"2024-05-03T04:25:51.068186Z","iopub.status.idle":"2024-05-03T04:25:58.298763Z","shell.execute_reply":"2024-05-03T04:25:58.297536Z","shell.execute_reply.started":"2024-05-03T04:25:51.068570Z"},"trusted":true},"outputs":[],"source":["# pip install pytorch-crf"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:25:58.301849Z","iopub.status.busy":"2024-05-03T04:25:58.301362Z","iopub.status.idle":"2024-05-03T04:26:01.642517Z","shell.execute_reply":"2024-05-03T04:26:01.641618Z","shell.execute_reply.started":"2024-05-03T04:25:58.301767Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import string\n","from unidecode import unidecode\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n","from transformers import AdamW, BertModel, AutoConfig, AutoTokenizer\n","from torch.optim import Adam\n","import torch.nn as nn\n","from transformers import AutoTokenizer, get_linear_schedule_with_warmup\n","import time\n","import datetime\n","from sklearn.model_selection import train_test_split\n","from torchcrf import CRF"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:26:01.644726Z","iopub.status.busy":"2024-05-03T04:26:01.644242Z","iopub.status.idle":"2024-05-03T04:26:01.676619Z","shell.execute_reply":"2024-05-03T04:26:01.675639Z","shell.execute_reply.started":"2024-05-03T04:26:01.644670Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["No GPU available, using the CPU instead.\n"]}],"source":["if torch.cuda.is_available():  \n","    device = torch.device(\"cuda\")\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","    \n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["Read data"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:26:01.678738Z","iopub.status.busy":"2024-05-03T04:26:01.678383Z","iopub.status.idle":"2024-05-03T04:26:01.809975Z","shell.execute_reply":"2024-05-03T04:26:01.809204Z","shell.execute_reply.started":"2024-05-03T04:26:01.678661Z"},"trusted":true},"outputs":[],"source":["nlp_train=pd.read_csv(\"train.csv\", index_col=[0])\n","nlp_test=pd.read_csv(\"test.csv\",index_col=[0],encoding=\"windows-1252\") \n","\n","#nlp_train=pd.read_csv(\"/kaggle/input/nlp-project-train/train.csv\", index_col=[0])\n","#nlp_test=pd.read_csv(\"/kaggle/input/nlp-project-train/test.csv\",index_col=[0],encoding=\"windows-1252\")"]},{"cell_type":"markdown","metadata":{},"source":["Functions to manipulate data"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:26:01.813583Z","iopub.status.busy":"2024-05-03T04:26:01.813253Z","iopub.status.idle":"2024-05-03T04:26:01.819304Z","shell.execute_reply":"2024-05-03T04:26:01.818412Z","shell.execute_reply.started":"2024-05-03T04:26:01.813534Z"},"trusted":true},"outputs":[],"source":["def convert_to_ascii(text):\n","    return unidecode(text)\n","\n","def remove_punctuations(text):\n","    for punctuation in string.punctuation:\n","        text = text.replace(punctuation, '')\n","        text = text.replace('  ', ' ')\n","    return text.strip()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:26:01.820975Z","iopub.status.busy":"2024-05-03T04:26:01.820641Z","iopub.status.idle":"2024-05-03T04:26:05.848093Z","shell.execute_reply":"2024-05-03T04:26:05.847360Z","shell.execute_reply.started":"2024-05-03T04:26:01.820931Z"},"trusted":true},"outputs":[],"source":["nlp_train['Sentence'] = nlp_train['Sentence'].apply(remove_punctuations)\n","nlp_train[\"Label\"] = nlp_train[\"Sentence\"]\n","nlp_train[\"Sentence\"] = nlp_train[\"Sentence\"].apply(convert_to_ascii)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:26:05.849643Z","iopub.status.busy":"2024-05-03T04:26:05.849292Z","iopub.status.idle":"2024-05-03T04:26:05.853906Z","shell.execute_reply":"2024-05-03T04:26:05.853037Z","shell.execute_reply.started":"2024-05-03T04:26:05.849593Z"},"trusted":true},"outputs":[],"source":["sentences_train, labels_train = nlp_train.Sentence.values, nlp_train.Label.values"]},{"cell_type":"markdown","metadata":{},"source":["Tokenizer"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:26:05.855486Z","iopub.status.busy":"2024-05-03T04:26:05.855121Z","iopub.status.idle":"2024-05-03T04:26:06.491370Z","shell.execute_reply":"2024-05-03T04:26:06.490350Z","shell.execute_reply.started":"2024-05-03T04:26:05.855425Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")"]},{"cell_type":"markdown","metadata":{},"source":["Functions to segment data"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:26:06.493376Z","iopub.status.busy":"2024-05-03T04:26:06.492883Z","iopub.status.idle":"2024-05-03T04:26:06.501920Z","shell.execute_reply":"2024-05-03T04:26:06.501035Z","shell.execute_reply.started":"2024-05-03T04:26:06.493299Z"},"trusted":true},"outputs":[],"source":["def segment_text(sentence, label, max_length=128, overlap=50):\n","    tokens = tokenizer.tokenize(sentence)\n","    new = []\n","    if len(tokens) <= max_length:\n","        return sentence, label\n","    else: \n","        return None, None\n","    \n","    \n","def data_segments(sentences, labels, max_length=32):\n","    all_text = []\n","    all_labels = []\n","\n","    for sentence, label in zip(sentences, labels):\n","        segment_s, segment_l = segment_text(sentence, label, max_length=max_length, overlap=50)\n","        if segment_s:\n","            all_text.append(segment_s)\n","            all_labels.append(segment_l)\n","            \n","    return all_text, all_labels"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:26:06.503607Z","iopub.status.busy":"2024-05-03T04:26:06.503301Z","iopub.status.idle":"2024-05-03T04:26:36.191415Z","shell.execute_reply":"2024-05-03T04:26:36.190670Z","shell.execute_reply.started":"2024-05-03T04:26:06.503567Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (6086 > 512). Running this sequence through the model will result in indexing errors\n"]}],"source":["train_sentences_segment, train_labels_segment = data_segments(sentences_train, labels_train)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:26:36.193295Z","iopub.status.busy":"2024-05-03T04:26:36.192839Z","iopub.status.idle":"2024-05-03T04:26:54.040339Z","shell.execute_reply":"2024-05-03T04:26:54.039239Z","shell.execute_reply.started":"2024-05-03T04:26:36.193223Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/mustafa/miniconda3/envs/nlp_project/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[2, 16751, 1066, 8725, 1992, 29252, 4456, 22063, 5484, 18740, 13526, 1027, 26905, 24419, 3575, 1028, 2031, 21070, 2194, 1996, 5538, 14330, 2033, 2002, 9474, 2293, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","sinif havuz ve acik deniz calismalariyla tum dunyada gecerli basarili bir standart olusturmustur\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["indices=tokenizer.batch_encode_plus(train_sentences_segment,max_length=128,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n","input_ids=indices[\"input_ids\"]\n","attention_masks=indices[\"attention_mask\"]\n","print(input_ids[0])\n","print(train_sentences_segment[0])\n","print(attention_masks[0])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:26:54.041853Z","iopub.status.busy":"2024-05-03T04:26:54.041553Z","iopub.status.idle":"2024-05-03T04:27:11.399438Z","shell.execute_reply":"2024-05-03T04:27:11.398456Z","shell.execute_reply.started":"2024-05-03T04:26:54.041815Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[2, 3825, 8725, 1992, 2416, 4456, 24513, 2525, 5292, 5953, 4165, 1996, 5538, 27202, 2293, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","sınıf havuz ve açık deniz çalışmalarıyla tüm dünyada geçerli başarılı bir standart oluşturmuştur\n"]}],"source":["indices=tokenizer.batch_encode_plus(train_labels_segment,max_length=128,add_special_tokens=True, return_attention_mask=True,pad_to_max_length=True,truncation=True)\n","output_ids=indices[\"input_ids\"]\n","print(output_ids[0])\n","print(train_labels_segment[0])"]},{"cell_type":"markdown","metadata":{},"source":["Prepare train and test data"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:27:11.401421Z","iopub.status.busy":"2024-05-03T04:27:11.401001Z","iopub.status.idle":"2024-05-03T04:27:12.191432Z","shell.execute_reply":"2024-05-03T04:27:12.190173Z","shell.execute_reply.started":"2024-05-03T04:27:11.401374Z"},"trusted":true},"outputs":[],"source":["# Use 99% for training and 1% for validation.\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,output_ids, \n","                                                            random_state=42, test_size=0.2)\n","# Do the same for the masks.\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, output_ids,\n","                                             random_state=42, test_size=0.2)\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels, dtype=torch.long)\n","validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n","train_masks = torch.tensor(train_masks, dtype=torch.long)\n","validation_masks = torch.tensor(validation_masks, dtype=torch.long)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:27:12.193090Z","iopub.status.busy":"2024-05-03T04:27:12.192748Z","iopub.status.idle":"2024-05-03T04:27:12.199340Z","shell.execute_reply":"2024-05-03T04:27:12.198422Z","shell.execute_reply.started":"2024-05-03T04:27:12.193040Z"},"trusted":true},"outputs":[],"source":["def format_time(elapsed):\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"markdown","metadata":{},"source":["## Combined Model"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:27:12.201047Z","iopub.status.busy":"2024-05-03T04:27:12.200750Z","iopub.status.idle":"2024-05-03T04:27:12.212502Z","shell.execute_reply":"2024-05-03T04:27:12.211441Z","shell.execute_reply.started":"2024-05-03T04:27:12.201008Z"},"trusted":true},"outputs":[],"source":["# unique_labels = nlp_train['Label'].unique()\n","# num_labels = len(unique_labels)\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-cased\")\n","# encoded_batch = tokenizer(train_sentences_segment, padding=True, truncation=True, return_tensors=\"pt\")\n","# input_ids = encoded_batch['input_ids']\n","# attention_mask_train = encoded_batch['attention_mask']\n","\n","# train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","# train_sampler = RandomSampler(train_data)\n","# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:27:12.214192Z","iopub.status.busy":"2024-05-03T04:27:12.213807Z","iopub.status.idle":"2024-05-03T04:27:12.229902Z","shell.execute_reply":"2024-05-03T04:27:12.228848Z","shell.execute_reply.started":"2024-05-03T04:27:12.214098Z"},"trusted":true},"outputs":[],"source":["# class BertBiLSTMCRF(nn.Module):\n","#     def __init__(self, bert_model, num_labels, lstm_hidden_dim):\n","#         super(BertBiLSTMCRF, self).__init__()\n","#         self.bert = BertModel.from_pretrained(bert_model)\n","#         self.lstm = nn.LSTM(input_size=self.bert.config.hidden_size,\n","#                             hidden_size=lstm_hidden_dim,\n","#                             num_layers=1,\n","#                             bidirectional=True,\n","#                             batch_first=True)\n","#         self.dropout = nn.Dropout(0.1)\n","#         self.classifier = nn.Linear(lstm_hidden_dim * 2, num_labels)\n","#         self.crf = CRF(num_labels, batch_first=True)\n","\n","#     def forward(self, input_ids, attention_mask=None, labels=None):\n","#         outputs = self.bert(input_ids, attention_mask=attention_mask)\n","#         sequence_output = outputs[0]\n","#         lstm_output, _ = self.lstm(sequence_output)\n","#         lstm_output = self.dropout(lstm_output)\n","#         logits = self.classifier(lstm_output)\n","#         if labels is not None:\n","#             loss = -self.crf(logits, labels, mask=attention_mask.byte())\n","#             return loss, logits\n","#         else:\n","#             return logits\n","\n","#     def predict(self, input_ids, attention_mask=None):\n","#         with torch.no_grad():\n","#             logits = self.forward(input_ids, attention_mask)\n","#             return self.crf.decode(logits, mask=attention_mask.byte())\n","        \n","        \n","class BertBiLSTMCRF(nn.Module):\n","    def __init__(self, bert_model, num_labels, lstm_hidden_dim, lstm_layers=1):\n","        super(BertBiLSTMCRF, self).__init__()\n","        self.bert = BertModel.from_pretrained(bert_model)\n","        self.lstm = nn.LSTM(input_size=self.bert.config.hidden_size,\n","                            hidden_size=lstm_hidden_dim,\n","                            num_layers=lstm_layers,\n","                            bidirectional=True,\n","                            batch_first=True)\n","        self.dropout = nn.Dropout(0.1)\n","        self.classifier = nn.Linear(lstm_hidden_dim * 2, num_labels)\n","        self.crf = CRF(num_labels, batch_first=True)\n","\n","    def forward(self, input_ids, attention_mask=None, labels=None):\n","        outputs = self.bert(input_ids, attention_mask=attention_mask)\n","        sequence_output = outputs[0]\n","        lstm_output, _ = self.lstm(sequence_output)\n","        lstm_output = self.dropout(lstm_output)\n","        logits = self.classifier(lstm_output)\n","        if labels is not None:\n","            loss = -self.crf(logits, labels, mask=attention_mask.byte())  # Calculate loss using CRF\n","            return loss, logits\n","        else:\n","            return logits\n","\n","    def predict(self, input_ids, attention_mask=None):\n","        with torch.no_grad():\n","            logits = self.forward(input_ids, attention_mask)\n","            return self.crf.decode(logits, mask=attention_mask.byte())"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:27:12.231637Z","iopub.status.busy":"2024-05-03T04:27:12.231256Z","iopub.status.idle":"2024-05-03T04:27:12.251303Z","shell.execute_reply":"2024-05-03T04:27:12.250232Z","shell.execute_reply.started":"2024-05-03T04:27:12.231587Z"},"trusted":true},"outputs":[],"source":["def train_model(model, train_dataloader, validation_dataloader, device, epochs=4, gradient_accumulation_steps=1):\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.95)\n","    \n","    for epoch_i in range(epochs):\n","        print(f'======== Epoch {epoch_i + 1} / {epochs} ========')\n","        total_train_loss = 0\n","        \n","        model.train()\n","        for step, batch in enumerate(train_dataloader):\n","            batch = tuple(t.to(device) for t in batch)\n","            b_input_ids, b_input_mask, b_labels = batch\n","            \n","            model.zero_grad()        \n","            loss, logits = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n","            \n","            loss = loss / gradient_accumulation_steps\n","            loss.backward()\n","            \n","            total_train_loss += loss.item()\n","            if (step + 1) % gradient_accumulation_steps == 0:\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","                optimizer.step()\n","                scheduler.step()\n","                model.zero_grad()\n","            \n","            if step % 40 == 0 and not step == 0:\n","                print(f'  Batch {step:>5,} of {len(train_dataloader):>5,}. Loss: {loss.item():.2f}')\n","        \n","        avg_train_loss = total_train_loss / len(train_dataloader)\n","        print(f\"  Average training loss: {avg_train_loss:.2f}\")\n","\n","        print(\"\\nRunning Validation...\")\n","        total_eval_accuracy = 0\n","        total_eval_loss = 0\n","        model.eval()\n","\n","        for batch in validation_dataloader:\n","            batch = tuple(t.to(device) for t in batch)\n","            b_input_ids, b_input_mask, b_labels = batch\n","            \n","            with torch.no_grad():\n","                loss, logits = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n","            \n","            total_eval_loss += loss.item()\n","            \n","            logits = logits.detach().cpu().numpy()\n","            label_ids = b_labels.to('cpu').numpy()\n","            total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","        print(f\"  Validation accuracy: {avg_val_accuracy:.2f}\")\n","        avg_val_loss = total_eval_loss / len(validation_dataloader)\n","        print(f\"  Validation Loss: {avg_val_loss:.2f}\")\n","\n","    print(\"done\")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:27:12.252950Z","iopub.status.busy":"2024-05-03T04:27:12.252590Z","iopub.status.idle":"2024-05-03T04:27:17.079279Z","shell.execute_reply":"2024-05-03T04:27:17.078219Z","shell.execute_reply.started":"2024-05-03T04:27:12.252899Z"},"trusted":true},"outputs":[],"source":["num_labels = len(set(train_sentences_segment))\n","# num_labels = len(unique_labels)\n","# num_labels=5\n","lstm_hidden_dim = 64\n","bert_model = 'dbmdz/bert-base-turkish-cased'\n","epochs = 1\n","batch_size = 1\n","gradient_accumulation_steps = 5\n","\n","# model = BertBiLSTMCRF(bert_model, num_labels, lstm_hidden_dim)\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","torch.cuda.empty_cache()\n","\n","model = BertBiLSTMCRF(bert_model, num_labels, lstm_hidden_dim)\n","model.bert = model.bert.to(device)\n","# Do some operations if necessary\n","model.lstm = model.lstm.to(device)\n","model.classifier = model.classifier.to(device)\n","model.crf = model.crf.to(device)\n","\n","# model.to(device)\n","\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_loader = DataLoader(validation_data, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T04:27:17.080969Z","iopub.status.busy":"2024-05-03T04:27:17.080615Z","iopub.status.idle":"2024-05-03T04:27:17.704494Z","shell.execute_reply":"2024-05-03T04:27:17.702105Z","shell.execute_reply.started":"2024-05-03T04:27:17.080916Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["======== Epoch 1 / 1 ========\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mustafa/miniconda3/envs/nlp_project/lib/python3.11/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorCompare.cpp:530.)\n","  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"]}],"source":["train_model(model, train_loader, validation_loader, device, epochs, gradient_accumulation_steps)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":843370,"sourceId":1439227,"sourceType":"datasetVersion"},{"datasetId":4789828,"sourceId":8108889,"sourceType":"datasetVersion"},{"datasetId":4789802,"sourceId":8283698,"sourceType":"datasetVersion"}],"dockerImageVersionId":29860,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
